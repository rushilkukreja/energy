{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNp3/MKOON4n9b0Bzg1kmd1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yV4ajlinYkwl","executionInfo":{"status":"ok","timestamp":1723705383181,"user_tz":240,"elapsed":1609003,"user":{"displayName":"Anush Devkar","userId":"00866563178925365326"}},"outputId":"4fbc89f2-8d76-4e97-918f-ba1e443acd49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 123ms/step - loss: 0.0183 - val_loss: 0.0068 - learning_rate: 0.0010\n","Epoch 2/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 121ms/step - loss: 0.0072 - val_loss: 0.0068 - learning_rate: 0.0010\n","Epoch 3/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 123ms/step - loss: 0.0065 - val_loss: 0.0063 - learning_rate: 0.0010\n","Epoch 4/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 123ms/step - loss: 0.0060 - val_loss: 0.0059 - learning_rate: 0.0010\n","Epoch 5/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 123ms/step - loss: 0.0061 - val_loss: 0.0056 - learning_rate: 0.0010\n","Epoch 6/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 125ms/step - loss: 0.0060 - val_loss: 0.0063 - learning_rate: 0.0010\n","Epoch 7/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 121ms/step - loss: 0.0060 - val_loss: 0.0055 - learning_rate: 0.0010\n","Epoch 8/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - loss: 0.0058 - val_loss: 0.0055 - learning_rate: 0.0010\n","Epoch 9/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 126ms/step - loss: 0.0058 - val_loss: 0.0051 - learning_rate: 0.0010\n","Epoch 10/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 122ms/step - loss: 0.0056 - val_loss: 0.0050 - learning_rate: 0.0010\n","Epoch 11/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 124ms/step - loss: 0.0053 - val_loss: 0.0051 - learning_rate: 0.0010\n","Epoch 12/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 124ms/step - loss: 0.0052 - val_loss: 0.0048 - learning_rate: 0.0010\n","Epoch 13/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 123ms/step - loss: 0.0052 - val_loss: 0.0047 - learning_rate: 0.0010\n","Epoch 14/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 122ms/step - loss: 0.0051 - val_loss: 0.0055 - learning_rate: 0.0010\n","Epoch 15/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 122ms/step - loss: 0.0052 - val_loss: 0.0047 - learning_rate: 0.0010\n","Epoch 16/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 121ms/step - loss: 0.0048 - val_loss: 0.0047 - learning_rate: 0.0010\n","Epoch 17/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - loss: 0.0050 - val_loss: 0.0051 - learning_rate: 0.0010\n","Epoch 18/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 120ms/step - loss: 0.0049 - val_loss: 0.0045 - learning_rate: 0.0010\n","Epoch 19/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 121ms/step - loss: 0.0050 - val_loss: 0.0047 - learning_rate: 0.0010\n","Epoch 20/20\n","\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 122ms/step - loss: 0.0049 - val_loss: 0.0046 - learning_rate: 0.0010\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.0044\n","Test loss: 0.00448598200455308\n","\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n","Mean Squared Error: 1426293.4605242468\n","Mean Absolute Error: 900.1343212716793\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import matplotlib.pyplot as plt\n","\n","# Load and preprocess data\n","df = pd.read_excel('/content/Los Angeles.xlsx')\n","df = df.dropna()\n","\n","temperature = df['Temperature'].values.reshape(-1, 1)\n","energy_demand = df['EnergyDemand'].values.reshape(-1, 1)\n","\n","scaler_temp = MinMaxScaler()\n","scaler_energy = MinMaxScaler()\n","temperature_normalized = scaler_temp.fit_transform(temperature)\n","energy_demand_normalized = scaler_energy.fit_transform(energy_demand)\n","\n","def create_sequences(data, seq_length):\n","    sequences = []\n","    targets = []\n","    for i in range(len(data) - seq_length):\n","        seq = data[i:i+seq_length]\n","        target = data[i+seq_length]\n","        sequences.append(seq)\n","        targets.append(target)\n","    return np.array(sequences), np.array(targets)\n","\n","seq_length = 48  # changed (doubled)\n","X, y = create_sequences(temperature_normalized, seq_length)\n","y = energy_demand_normalized[seq_length:]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# more units, extra gru layer, 2 dropouts\n","model = Sequential([\n","    GRU(100, activation='tanh', return_sequences=True, input_shape=(seq_length, 1)),\n","    Dropout(0.2),\n","    GRU(50, activation='tanh'),\n","    Dropout(0.2),\n","    Dense(25, activation='relu'),\n","    Dense(1)\n","])\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n","\n","# changed\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n","\n","\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=20, #changed --> increase more bc early stopping is implemented\n","    batch_size=64, #changed\n","    validation_split=0.1,\n","    callbacks=[early_stopping, reduce_lr],\n","    verbose=1\n",")\n","\n","loss = model.evaluate(X_test, y_test)\n","print(f\"Test loss: {loss}\")\n","\n","predictions_normalized = model.predict(X_test)\n","\n","predictions = scaler_energy.inverse_transform(predictions_normalized)\n","y_test_original = scaler_energy.inverse_transform(y_test)\n","\n","mse = mean_squared_error(y_test_original, predictions)\n","mae = mean_absolute_error(y_test_original, predictions)\n","print(f\"Mean Squared Error: {mse}\")\n","print(f\"Mean Absolute Error: {mae}\")"]}]}