{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJjn9MR7npLL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def preprocess_city_data(file_path):\n",
        "    df = pd.read_excel(file_path)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df['Hour'] = pd.to_datetime(df['Time']).dt.hour\n",
        "    df['DayOfWeek'] = pd.to_datetime(df['Time']).dt.dayofweek\n",
        "    df['Month'] = pd.to_datetime(df['Time']).dt.month\n",
        "    df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)\n",
        "\n",
        "\n",
        "    for lag in range(1, 25):\n",
        "        df[f'Lag_{lag}'] = df['EnergyDemand'].shift(lag)\n",
        "\n",
        "    df['Temp_RollingMean_24'] = df['Temperature'].rolling(window=24).mean()\n",
        "    df['Temp_RollingStd_24'] = df['Temperature'].rolling(window=24).std()\n",
        "\n",
        "    df['Temp_Humidity_Interaction'] = df['Temperature'] * df['RelativeHumidity']\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "cities_data = []\n",
        "city_files = {\n",
        "    'Chicago': 'Chicago.xlsx',\n",
        "    'Philadelphia': 'Philadelphia.xlsx',\n",
        "    'Houston': 'Houston.xlsx'\n",
        "}\n",
        "\n",
        "for city, file_path in city_files.items():\n",
        "    city_data = preprocess_city_data(file_path)\n",
        "    city_data['City'] = city\n",
        "    cities_data.append(city_data)\n",
        "\n",
        "\n",
        "df_all = pd.concat(cities_data, ignore_index=True)\n",
        "\n",
        "\n",
        "features = df_all[['Temperature', 'DewPoint', 'RelativeHumidity', 'Precipitation', 'WindSpeed', 'Pressure',\n",
        "                   'Hour', 'DayOfWeek', 'Month', 'IsWeekend',\n",
        "                   'Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5', 'Lag_6', 'Lag_7', 'Lag_8', 'Lag_9', 'Lag_10',\n",
        "                   'Lag_11', 'Lag_12', 'Lag_13', 'Lag_14', 'Lag_15', 'Lag_16', 'Lag_17', 'Lag_18', 'Lag_19',\n",
        "                   'Lag_20', 'Lag_21', 'Lag_22', 'Lag_23', 'Lag_24',\n",
        "                   'Temp_RollingMean_24', 'Temp_RollingStd_24',\n",
        "                   'Temp_Humidity_Interaction']].values\n",
        "energy_demand = df_all['EnergyDemand'].values.reshape(-1, 1)\n",
        "dates = df_all['Time'].values\n",
        "\n",
        "\n",
        "scaler_features = MinMaxScaler()\n",
        "scaler_energy = MinMaxScaler()\n",
        "features_normalized = scaler_features.fit_transform(features)\n",
        "energy_demand_normalized = scaler_energy.fit_transform(energy_demand)\n",
        "\n",
        "def create_sequences(data, target, dates, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    sequence_dates = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        seq = data[i:i+seq_length]\n",
        "        target_seq = target[i+seq_length]\n",
        "        date_seq = dates[i+seq_length]\n",
        "        sequences.append(seq)\n",
        "        targets.append(target_seq)\n",
        "        sequence_dates.append(date_seq)\n",
        "    return np.array(sequences), np.array(targets), np.array(sequence_dates)\n",
        "\n",
        "seq_length = 24\n",
        "X, y, dates_seq = create_sequences(features_normalized, energy_demand_normalized, dates, seq_length)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "\n",
        "mse_scores = []\n",
        "mae_scores = []\n",
        "mape_scores = []\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    non_zero_indices = y_true != 0\n",
        "    return np.mean(np.abs((y_true[non_zero_indices] - y_pred[non_zero_indices]) / y_true[non_zero_indices])) * 100\n",
        "\n",
        "result_df = pd.DataFrame()\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    dates_test = dates_seq[test_index]\n",
        "\n",
        "    model = Sequential([\n",
        "        LSTM(50, activation='relu', input_shape=(seq_length, X.shape[2])),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "    # Making predictions\n",
        "    predictions_normalized = model.predict(X_test)\n",
        "    predictions = scaler_energy.inverse_transform(predictions_normalized)\n",
        "    y_test_original = scaler_energy.inverse_transform(y_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_test_original, predictions)\n",
        "    mae = mean_absolute_error(y_test_original, predictions)\n",
        "    mape = mean_absolute_percentage_error(y_test_original, predictions)\n",
        "    mse_scores.append(mse)\n",
        "    mae_scores.append(mae)\n",
        "    mape_scores.append(mape)\n",
        "\n",
        "    # Store results\n",
        "    fold_results = pd.DataFrame({\n",
        "        'Date': dates_test,\n",
        "        'Actual': y_test_original.flatten(),\n",
        "        'Predicted': predictions.flatten()\n",
        "    })\n",
        "    result_df = pd.concat([result_df, fold_results], ignore_index=True)\n",
        "\n",
        "\n",
        "result_df.to_csv('all_cities_predictions.csv', index=False)\n",
        "\n",
        "\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_mape = np.mean(mape_scores)\n",
        "print(f\"Average Mean Squared Error: {average_mse}\")\n",
        "print(f\"Average Mean Absolute Error: {average_mae}\")\n",
        "print(f\"Average Mean Absolute Percentage Error: {average_mape}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(result_df['Actual'][:100], label='Actual')\n",
        "plt.plot(result_df['Predicted'][:100], label='Predicted')\n",
        "plt.title('Predicted vs Actual Energy Demand (Last Fold)')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Energy Demand')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}